# Week 1: Introduction to Data Cleaning
- Cost resulting from low-quality data
- Data cleaning idea (steps)
	1. Quality dimensions
	1. Ask questions around quality
	1. Executing queries to get the answers of the questions
		- e.g. data profiling, data cleaning, data integration
- Taxonomy of error types
	1. Quantitiative
	1. Qualitative (focus of the course)
		- Syntactic (covered in week 2 - 3)
			- can use regex
		- Schema / Integrity Constraint Violations / Semantics (covered in week 4 - 6)
			- can use database / SQL
		- Synthesis
			- Workflow automation
			- Provenance
			- YesWorkflow
		- Duplicates
- Data Quality (DQ)
	- Fitness for use (Fitness for Purpose)
		- fit for use when they are free of defects and possess the features needed to complete use cases
- Pillars of DQ
	1. Organizational
	1. Architectural
	1. Computational
- DQ management phases
- DQ dimensions


# Week 2: Regular Expressions (Syntax)

## Theory
- A formal expression that defines a search pattern
	- Used to match, extract, find-and-replace data
- Why used in data cleaning?
	- Useful to match (assess) and transform (clean) data
- Chomsky Hierarchy

## Practice
- False negative
	- your pattern doe not match although it should!
- False Positive
	- your pattern does match although it shouldn’t!
- Tools
	1. OpenRefine

# Week 3: OpenRefine (Syntax)
- A power tool for data "wrangling"
	- Data wrangling is the process of converting raw data into a usable form
- Features
	1. Provides an overview (exploring and "profiling") of data
		- e.g. Faceting (text, timeline, scatterplot)
	1. Can detect and clean certain data errors
	1. Can transform and link data
		- e.g. 
			1. convert data types, mass edit
			1. Basic normalization
				- e.g. Triming whitespaces
			1. Clustering
				1. Key collision
				1. Nearest neighbour
	1. Operation History for provenance


# Week 4: Relational (Schema & Semantics)
- Query languages for checking of integrity constraints
	1. FOL (First-order predicate logic; Not very common)
	1. Datalog
		- Relational calculus + recursion
	1. Relational Algebra
	1. SQL



# Week 5: Datalog & Integrity Constraint
- Semantics / ICs in Conceptual Models (e.g. ER, UML) can express
	1. functional dependencies (key constraints)
		- one or more columns provide a unique key
	1. inclusion dependencies (foreign key constraints)
		- referential ICs
	1. cardinality constraints
	1. hierarchical constraints (class hierarchy)
- IC repair
	- Minimal repair
	- ASP (Answer Set Programming)
		- Datalog + AI-ish “Generate & Test” paradigm



# Week 6: SQL(ite)

## SQLite commands
1. `.schema` returns all existing tables in the DB with the schemas
1. `select A, count(B), avg(C) from _ where _ = '' AND ... GROUP BY A, D ORDER BY A`
	- `group by` - aggregate records
1. `select A || " " || B AS C FROM ...` concat A and B with a ' ' in between
1. `select group_concat(A, ",") FROM ...` concat the result from all rows with ',' as the delimiter.
1. Recursion
```
WITH RECURSIVE
new_relation(a) AS (
	VALUES(initial_value_A)
	UNION
	SELECT A
	FROM _, new_relation
	WHERE _.B = new_relation.a
)
```


# Week 7: Workflows
- Workflows are used to describe and automate data cleaning and analysis "pipelines."
	- Can also combine manual or semi-automatic steps (e.g., in OpenRefine) with fully automatic steps (e.g., using Python, R scripts, or SQL queries)
- ASAP (scientific workflow)
	1. Automation
	1. Scaling
	1. Abstraction, evolution, re-use
		- easy to (re-)use, evolve, share
			- i.e. readability - documentation; dataflow diagram
	1. Provenance
		- capture processing history, data lineage
- Essential Functions of a Scientific Workflow System
- WATERS Workflow
- Kepler Workflows


# Week 8: Provenance


# MP 5
- clingo re-visit
	- Comma means AND operator: 
		1. grandparent(X,Y) :- parent(X, Z), parent(Z, Y).
		1. father(X,Y)  :-     parent(X, Y), male(X).