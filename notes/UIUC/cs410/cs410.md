# Week 1

## Intro
- Motivation: harnessing Big text data
	- Text retrievalï¼šwhich helps identify the most relevant text data to a particular problem from a large collection of text documents, thus avoiding processing a large number of non-relevant documents	
		- converts big text data into smaller relevant data
	- Text mining, which helps users further analyze and digest the found relevant text data and extract actionable knowledge for finishing a task	
		- converts smaller data into knowledge

## Natural Language Content Analysis

### Natural Language Processing
- Progression
	1. Lexical analysis (speech tagging): figure out which words are nouns, verbs, adjectives, etc.
	1. Syntactic analysis
	1. Semantic analysis
	1. (Optional) Inference
	1. Pragmatic analysis: why someone say this sentence

### State of art
- Can do lexical analysis and partial syntactic analysis pretty well

### NLP for text retrieval

## Text Access

## TR (Text Retrieval) Problem
- TR (Text Retrieval)
	- A task where the system would respond to a user's query with relevant documents.
	- Supporting pull mode of info access
	- e.g. search in google
	- TR is a subset of IR (information retrieval), which also includes retrieving non-textual information including video, audio, etc
- TR vs Database query
	1. Information
		1. Unstructured vs structured
		1. Ambiguous vs well-defined semantics
	1. Query
		1. Ambiguous vs well-defined semantics
	1. Answers
		1. No 'right' answers vs matched recorded
	1. TR is an empirically defined problem
		- Effectiveness is evaluated by users

### Formal Formulation
1. Vocab: $$ V = {w_1, w_2, ... }$$ of language
1. Query: $$ q = q_1, q_2, ... q_m, where q_i \in V $$ (i.e. a sequence of words)
1. Document: $$ d_i = d_{i1}, ..., d_{im_j}, where d_{ij} \in V $$ (i.e. each document is a sequence of words, but typically is longer than a query)

### Solving TR Problems
1. Document selection
1. Document ranking
	- $$ f(d, q) $$ where d is one of the docs, and q is the query. f returns a score which will be evaluated against a threshold
	- generally preferred
	- challenge: define an effective ranking function


## TR Methods
1. Similarity-based models
1. Probabilistic models
1. Probabilistic inference model
1. Axiomatic model

### Bag of words
- $$ f(q, d) = \sum_{i = 1 ... n} g(q_i, d) $$ where g is the weight of each words, which represents how well the doc matches each of the query words
	- Thus the total score depends on the score of each word
- Term frequency
	- how many times does a word occur in a doc
	- also denoted as $$ c(w, d) $$
- Document frequency
	- how many docs contain the word
	- also denoted as $$ df(w) $$
- Certain information about text is lost
	1. word ordering
	1. phrases formed by multiple words


## VSM (Vector Space Model)
- A similarity based model


## VSM Simple Instantiation

# Week 2

## VSM Improved Instantiation

## TF Transformation

## Doc Length Normalization
- Pivoted Length Normalization

# Week 3

# Week 4: Probabilistic Retrieval Model
- Model: $$ f(d,q) = p(R=1|d,q), R \in {0,1} \approx p(q|d, R=1) $$
	- $$ p(R=1|d,q) $$: given the query q and returned doc d, the probability that d is relavant
	- $$ p(q|d, R=1) $$: given the relavant doc d, how likely would the user enters query q to retrieve d.
- Language Model: query likelihood 

## Statistical Language Model
- A probability distribution over word sequences
- Stat LM features
	1. Context dependent
- LM benefits
	1. speech recognition
	1. text categorization
	1. information retrieval

### Unigram LM
- Features
	1. Ignore context
	1. Generating each word independently
	1. Order does not matter
- Unigram Query Likelihood
	- $$ p(q|d) = p(w_1,w_2,w_3,...|d) = p(w_1)*p(w_2)*p(w_3)... $$ (due to independence)
	- Use document language model (to prevent 0 probability) and log (to avoid having a lot of small probabilities)
		- $$ f(q,d) = log(p(q|d)) = \sum^n_{i=1}log(p(w_i|d)) = \sum_{w \in V}c(w,q) * log(p(w|d)) $$
			- How to estimate $$p(w|d)$$?
				- Smoothing

## Smoothing
- Rewriting the formula with smoothing
	- $$ f(q,d) = log(p(q|d)) = \sum_{w \in V}c(w,q) * log(p(w|d)) = \sum_{w \in V, c(w,d)>0}c(w,q)log(p_{Seen}(w|d)) + \sum_{w \in V}c(w,q)log(\alpha * p(w|C)) - \sum_{w \in V, c(w,d)>0}c(w,q)log(\alpha * p(w|C)) = \sum_{w \in V, c(w,d)>0}c(w,q)log(\frac{p_{Seen}(w|d)}{\alpha * p(w|C)}) + |q|log(\alpha) + \sum_{w \in V}log(p(w|C)) $$

## Smoothing Methods
1. Linear Interpolation (Jelinek-Mercer) Smoothing
1. Dirichlet Prior (Bayesian) Smoothing

# Week 5

## Web Search

### Crawler
- Crawling Strategies
	1. Breadth-First
		- balances server load automatically
	1. Parallel crawling
	1. Focused crawling
	1. Incremental (repeated) crawling
- Crawling Senarios
	1. Initial crawling
		1. Complete crawling
			- e.g. creating a general search engine
		1. Focused
			- e.g. target a certain type of pages
	1. Incremental crawling
		- i.e. incremental updating of the crawl data
		- try to use minimum resource to get the data
- A crawler that only follows hyperlinks cannot identify hidden pages that do not have any incoming links

### Indexer
- Components
	1. GFS
	1. MapReduce
		- Framework for parallel programming
		- Benefits
			1. Create index in parallel

### Retriever: PageRank
- Random jumping
	- Benefits
		1. Prevent zero-outlink nodes to receive all probability
		1. Allow disconnected pages to have non-zero probability



