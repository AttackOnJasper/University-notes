<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>cs410 | Jasper Wang</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script type="text/javascript">
  window.onload = function() {
    document.getElementsByClassName("status-banner")[0].style.display = "block";
    setTimeout(function() {
      renderMathElements(document.getElementsByClassName("math"));
      document.getElementsByClassName("status-banner")[0].style.display = "none";
    }, 50); // delay to allow status banner to show
  }

  function renderMathElements(mathElements) {
    var mathOptions = {
      macros: {
        "\\set": "\\left\\{ #1 \\right\\}",
        "\\tup": "\\left\\langle #1 \\right\\rangle",
        "\\abs": "\\left\\lvert #1 \\right\\rvert",
        "\\floor": "\\left\\lfloor #1 \\right\\rfloor",
        "\\ceil": "\\left\\lceil#1 \\right\\rceil",
        "\\mb": "\\mathbb{#1}",
        "\\rem": "\\operatorname{rem}",
        "\\ord": "\\operatorname{ord}",
        "\\sign": "\\operatorname{sign}",
        "\\imag": "\\bm{i}",
        "\\dee": "\\mathop{}\\!\\mathrm{d}",
        "\\lH": "\\overset{\\text{l'H}}{=}",
        "\\evalat": "\\left.\\left(#1\\right)\\right|",
        "\\sech": "\\operatorname{sech}",
        "\\spn": "\\operatorname{Span}",
        "\\proj": "\\operatorname{proj}",
        "\\prp": "\\operatorname{perp}",
        "\\refl": "\\operatorname{refl}",
        "\\magn": "\\left\\lVert #1 \\right\\rVert",
        "\\rank": "\\operatorname{rank}",
        "\\sys": "\\left[ #1 \\mid #2\\space \\right]",
        "\\range": "\\operatorname{Range}",
        "\\adj": "\\operatorname{adj}",
        "\\cof": "\\operatorname{cof}",
        "\\coord": "{\\left\\lbrack #1 \\right\\rbrack}_{#2}",
        "\\diag": "\\operatorname{diag}",
        "\\formlp": "\\operatorname{Form}(\\mathcal{L}^P)",

        // not yet available in KaTeX
        "\\operatorname": "\\mathop{\\text{#1}}\\nolimits", //wip: spacing is slightly off
        "\\not": "\\rlap{\\kern{7.5mu}/}", //wip: slash angle is slightly off
        "\\bm": "\\mathbf", //wip: should be italic, but isn't
      },
      throwOnError: false,
    };
    for (var i=0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      katex.render(texText.data, mathElements[i], mathOptions);
    }
  }
  </script>
</head>
<body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
<div id="TOC">
<ul>
<li><a href="#week-1">Week 1</a>
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#natural-language-content-analysis">Natural Language Content Analysis</a>
<ul>
<li><a href="#natural-language-processing">Natural Language Processing</a></li>
<li><a href="#state-of-art">State of art</a></li>
<li><a href="#nlp-for-text-retrieval">NLP for text retrieval</a></li>
</ul></li>
<li><a href="#text-access">Text Access</a></li>
<li><a href="#tr-text-retrieval-problem">TR (Text Retrieval) Problem</a>
<ul>
<li><a href="#formal-formulation">Formal Formulation</a></li>
<li><a href="#solving-tr-problems">Solving TR Problems</a></li>
</ul></li>
<li><a href="#tr-methods">TR Methods</a>
<ul>
<li><a href="#bag-of-words">Bag of words</a></li>
</ul></li>
<li><a href="#vsm-vector-space-model">VSM (Vector Space Model)</a></li>
<li><a href="#vsm-simple-instantiation">VSM Simple Instantiation</a></li>
</ul></li>
<li><a href="#week-2">Week 2</a>
<ul>
<li><a href="#vsm-improved-instantiation">VSM Improved Instantiation</a></li>
<li><a href="#tf-transformation">TF Transformation</a></li>
<li><a href="#doc-length-normalization">Doc Length Normalization</a></li>
</ul></li>
<li><a href="#week-3">Week 3</a></li>
<li><a href="#week-4-probabilistic-retrieval-model">Week 4: Probabilistic Retrieval Model</a>
<ul>
<li><a href="#statistical-language-model">Statistical Language Model</a>
<ul>
<li><a href="#unigram-lm">Unigram LM</a></li>
</ul></li>
<li><a href="#smoothing">Smoothing</a></li>
<li><a href="#smoothing-methods">Smoothing Methods</a></li>
</ul></li>
<li><a href="#week-5">Week 5</a>
<ul>
<li><a href="#web-search">Web Search</a>
<ul>
<li><a href="#crawler">Crawler</a></li>
<li><a href="#indexer">Indexer</a></li>
<li><a href="#retriever-pagerank">Retriever: PageRank</a></li>
</ul></li>
</ul></li>
</ul>
</div>
  <h1>Notes by <a href="/">Jasper Wang</a>.</h1>
  <ul class="site_links">
    <span class="divider"></span>
  </ul>
<h1 id="week-1">Week 1</h1>
<h2 id="intro">Intro</h2>
<ul>
<li>Motivation: harnessing Big text data
<ul>
<li>Text retrieval：which helps identify the most relevant text data to a particular problem from a large collection of text documents, thus avoiding processing a large number of non-relevant documents
<ul>
<li>converts big text data into smaller relevant data</li>
</ul></li>
<li>Text mining, which helps users further analyze and digest the found relevant text data and extract actionable knowledge for finishing a task
<ul>
<li>converts smaller data into knowledge</li>
</ul></li>
</ul></li>
</ul>
<h2 id="natural-language-content-analysis">Natural Language Content Analysis</h2>
<h3 id="natural-language-processing">Natural Language Processing</h3>
<ul>
<li>Progression
<ol type="1">
<li>Lexical analysis (speech tagging): figure out which words are nouns, verbs, adjectives, etc.</li>
<li>Syntactic analysis</li>
<li>Semantic analysis</li>
<li>(Optional) Inference</li>
<li>Pragmatic analysis: why someone say this sentence</li>
</ol></li>
</ul>
<h3 id="state-of-art">State of art</h3>
<ul>
<li>Can do lexical analysis and partial syntactic analysis pretty well</li>
</ul>
<h3 id="nlp-for-text-retrieval">NLP for text retrieval</h3>
<h2 id="text-access">Text Access</h2>
<h2 id="tr-text-retrieval-problem">TR (Text Retrieval) Problem</h2>
<ul>
<li>TR (Text Retrieval)
<ul>
<li>A task where the system would respond to a user’s query with relevant documents.</li>
<li>Supporting pull mode of info access</li>
<li>e.g. search in google</li>
<li>TR is a subset of IR (information retrieval), which also includes retrieving non-textual information including video, audio, etc</li>
</ul></li>
<li>TR vs Database query
<ol type="1">
<li>Information
<ol type="1">
<li>Unstructured vs structured</li>
<li>Ambiguous vs well-defined semantics</li>
</ol></li>
<li>Query
<ol type="1">
<li>Ambiguous vs well-defined semantics</li>
</ol></li>
<li>Answers
<ol type="1">
<li>No ‘right’ answers vs matched recorded</li>
</ol></li>
<li>TR is an empirically defined problem
<ul>
<li>Effectiveness is evaluated by users</li>
</ul></li>
</ol></li>
</ul>
<h3 id="formal-formulation">Formal Formulation</h3>
<ol type="1">
<li>Vocab: <span class="math display"> V = {w_1, w_2, ... }</span> of language</li>
<li>Query: <span class="math display"> q = q_1, q_2, ... q_m, where q_i \in V </span> (i.e. a sequence of words)</li>
<li>Document: <span class="math display"> d_i = d_{i1}, ..., d_{im_j}, where d_{ij} \in V </span> (i.e. each document is a sequence of words, but typically is longer than a query)</li>
</ol>
<h3 id="solving-tr-problems">Solving TR Problems</h3>
<ol type="1">
<li>Document selection</li>
<li>Document ranking
<ul>
<li><span class="math display"> f(d, q) </span> where d is one of the docs, and q is the query. f returns a score which will be evaluated against a threshold</li>
<li>generally preferred</li>
<li>challenge: define an effective ranking function</li>
</ul></li>
</ol>
<h2 id="tr-methods">TR Methods</h2>
<ol type="1">
<li>Similarity-based models</li>
<li>Probabilistic models</li>
<li>Probabilistic inference model</li>
<li>Axiomatic model</li>
</ol>
<h3 id="bag-of-words">Bag of words</h3>
<ul>
<li><span class="math display"> f(q, d) = \sum_{i = 1 ... n} g(q_i, d) </span> where g is the weight of each words, which represents how well the doc matches each of the query words
<ul>
<li>Thus the total score depends on the score of each word</li>
</ul></li>
<li>Term frequency
<ul>
<li>how many times does a word occur in a doc</li>
<li>also denoted as <span class="math display"> c(w, d) </span></li>
</ul></li>
<li>Document frequency
<ul>
<li>how many docs contain the word</li>
<li>also denoted as <span class="math display"> df(w) </span></li>
</ul></li>
<li>Certain information about text is lost
<ol type="1">
<li>word ordering</li>
<li>phrases formed by multiple words</li>
</ol></li>
</ul>
<h2 id="vsm-vector-space-model">VSM (Vector Space Model)</h2>
<ul>
<li>A similarity based model</li>
</ul>
<h2 id="vsm-simple-instantiation">VSM Simple Instantiation</h2>
<h1 id="week-2">Week 2</h1>
<h2 id="vsm-improved-instantiation">VSM Improved Instantiation</h2>
<h2 id="tf-transformation">TF Transformation</h2>
<h2 id="doc-length-normalization">Doc Length Normalization</h2>
<ul>
<li>Pivoted Length Normalization</li>
</ul>
<h1 id="week-3">Week 3</h1>
<h1 id="week-4-probabilistic-retrieval-model">Week 4: Probabilistic Retrieval Model</h1>
<ul>
<li>Model: <span class="math display"> f(d,q) = p(R=1|d,q), R \in {0,1} \approx p(q|d, R=1) </span>
<ul>
<li><span class="math display"> p(R=1|d,q) </span>: given the query q and returned doc d, the probability that d is relavant</li>
<li><span class="math display"> p(q|d, R=1) </span>: given the relavant doc d, how likely would the user enters query q to retrieve d.</li>
</ul></li>
<li>Language Model: query likelihood</li>
</ul>
<h2 id="statistical-language-model">Statistical Language Model</h2>
<ul>
<li>A probability distribution over word sequences</li>
<li>Stat LM features
<ol type="1">
<li>Context dependent</li>
</ol></li>
<li>LM benefits
<ol type="1">
<li>speech recognition</li>
<li>text categorization</li>
<li>information retrieval</li>
</ol></li>
</ul>
<h3 id="unigram-lm">Unigram LM</h3>
<ul>
<li>Features
<ol type="1">
<li>Ignore context</li>
<li>Generating each word independently</li>
<li>Order does not matter</li>
</ol></li>
<li>Unigram Query Likelihood
<ul>
<li><span class="math display"> p(q|d) = p(w_1,w_2,w_3,...|d) = p(w_1)*p(w_2)*p(w_3)... </span></li>
</ul></li>
</ul>
<h2 id="smoothing">Smoothing</h2>
<h2 id="smoothing-methods">Smoothing Methods</h2>
<ol type="1">
<li>Linear Interpolation (Jelinek-Mercer) Smoothing</li>
<li>Dirichlet Prior (Bayesian) Smoothing</li>
</ol>
<h1 id="week-5">Week 5</h1>
<h2 id="web-search">Web Search</h2>
<h3 id="crawler">Crawler</h3>
<ul>
<li>Crawling Strategies
<ol type="1">
<li>Breadth-First
<ul>
<li>balances server load automatically</li>
</ul></li>
<li>Parallel crawling</li>
<li>Focused crawling</li>
<li>Incremental (repeated) crawling</li>
</ol></li>
<li>Crawling Senarios
<ol type="1">
<li>Initial crawling
<ol type="1">
<li>Complete crawling
<ul>
<li>e.g. creating a general search engine</li>
</ul></li>
<li>Focused
<ul>
<li>e.g. target a certain type of pages</li>
</ul></li>
</ol></li>
<li>Incremental crawling
<ul>
<li>i.e. incremental updating of the crawl data</li>
<li>try to use minimum resource to get the data</li>
</ul></li>
</ol></li>
<li>A crawler that only follows hyperlinks cannot identify hidden pages that do not have any incoming links</li>
</ul>
<h3 id="indexer">Indexer</h3>
<ul>
<li>Components
<ol type="1">
<li>GFS</li>
<li>MapReduce
<ul>
<li>Framework for parallel programming</li>
<li>Benefits
<ol type="1">
<li>Create index in parallel</li>
</ol></li>
</ul></li>
</ol></li>
</ul>
<h3 id="retriever-pagerank">Retriever: PageRank</h3>
<ul>
<li>Random jumping
<ul>
<li>Benefits
<ol type="1">
<li>Prevent zero-outlink nodes to receive all probability</li>
<li>Allow disconnected pages to have non-zero probability</li>
</ol></li>
</ul></li>
</ul>
<div class="status-banner" style="display: none; position: fixed; bottom: 0; left: 0; right: 0; text-align: center;">
    <div style="display: inline-block; padding: 0.8em 2em 0.5em 2em; background: black; color: white; font-size: 2em;">
        Rendering <svg xmlns="http://www.w3.org/2000/svg" height="1.4em" viewbox="0 0 1200 500" style="vertical-align: text-bottom"><title>LaTeX logo</title><g transform="matrix(45 0 0 45 40 40)" fill="white"><path d="M5.5 4.4C5.5 4.4 5.2 4.4 5.2 4.4 5.1 5.4 5 6.7 3.2 6.7 3.2 6.7 2.4 6.7 2.4 6.7 1.9 6.7 1.9 6.6 1.9 6.3 1.9 6.3 1.9 1 1.9 1 1.9 0.6 1.9 0.5 2.9 0.5 2.9 0.5 3.2 0.5 3.2 0.5 3.2 0.5 3.2 0.2 3.2 0.2 2.8 0.2 1.9 0.2 1.5 0.2 1.1 0.2 0.3 0.2 0 0.2 0 0.2 0 0.5 0 0.5 0 0.5 0.2 0.5 0.2 0.5 1 0.5 1 0.6 1 0.9 1 0.9 1 6.2 1 6.2 1 6.6 1 6.7 0.2 6.7 0.2 6.7 0 6.7 0 6.7 0 6.7 0 7 0 7 0 7 5.2 7 5.2 7 5.2 7 5.5 4.4 5.5 4.4z"/><path d="M5.3 0.2C5.3 0 5.2 0 5.1 0 5 0 4.9 0 4.9 0.2 4.9 0.2 3.3 4.2 3.3 4.2 3.2 4.4 3.1 4.7 2.5 4.7 2.5 4.7 2.5 5 2.5 5 2.5 5 4 5 4 5 4 5 4 4.7 4 4.7 3.7 4.7 3.5 4.6 3.5 4.4 3.5 4.3 3.5 4.3 3.6 4.2 3.6 4.2 3.9 3.4 3.9 3.4 3.9 3.4 5.9 3.4 5.9 3.4 5.9 3.4 6.3 4.4 6.3 4.4 6.3 4.4 6.3 4.5 6.3 4.5 6.3 4.7 5.9 4.7 5.8 4.7 5.8 4.7 5.8 5 5.8 5 5.8 5 7.7 5 7.7 5 7.7 5 7.7 4.7 7.7 4.7 7.7 4.7 7.6 4.7 7.6 4.7 7.1 4.7 7.1 4.7 7 4.5 7 4.5 5.3 0.2 5.3 0.2zM4.9 0.9C4.9 0.9 5.8 3.1 5.8 3.1 5.8 3.1 4 3.1 4 3.1 4 3.1 4.9 0.9 4.9 0.9z"/><path d="M13.3 0.2C13.3 0.2 7.2 0.2 7.2 0.2 7.2 0.2 7 2.5 7 2.5 7 2.5 7.3 2.5 7.3 2.5 7.4 0.9 7.6 0.5 9.1 0.5 9.3 0.5 9.5 0.5 9.6 0.6 9.8 0.6 9.8 0.7 9.8 0.9 9.8 0.9 9.8 6.2 9.8 6.2 9.8 6.5 9.8 6.7 8.8 6.7 8.8 6.7 8.4 6.7 8.4 6.7 8.4 6.7 8.4 7 8.4 7 8.8 6.9 9.8 6.9 10.3 6.9 10.7 6.9 11.7 6.9 12.2 7 12.2 7 12.2 6.7 12.2 6.7 12.2 6.7 11.8 6.7 11.8 6.7 10.7 6.7 10.7 6.5 10.7 6.2 10.7 6.2 10.7 0.9 10.7 0.9 10.7 0.7 10.7 0.6 10.9 0.6 11 0.5 11.3 0.5 11.5 0.5 13 0.5 13.1 0.9 13.2 2.5 13.2 2.5 13.5 2.5 13.5 2.5 13.5 2.5 13.3 0.2 13.3 0.2z"/><path d="M18.7 6.7C18.7 6.7 18.4 6.7 18.4 6.7 18.2 8.2 17.9 8.9 16.2 8.9 16.2 8.9 14.9 8.9 14.9 8.9 14.4 8.9 14.4 8.8 14.4 8.5 14.4 8.5 14.4 5.9 14.4 5.9 14.4 5.9 15.3 5.9 15.3 5.9 16.3 5.9 16.4 6.2 16.4 7 16.4 7 16.6 7 16.6 7 16.6 7 16.6 4.4 16.6 4.4 16.6 4.4 16.4 4.4 16.4 4.4 16.4 5.2 16.3 5.5 15.3 5.5 15.3 5.5 14.4 5.5 14.4 5.5 14.4 5.5 14.4 3.2 14.4 3.2 14.4 2.8 14.4 2.8 14.9 2.8 14.9 2.8 16.2 2.8 16.2 2.8 17.7 2.8 18 3.3 18.1 4.7 18.1 4.7 18.4 4.7 18.4 4.7 18.4 4.7 18.1 2.5 18.1 2.5 18.1 2.5 12.5 2.5 12.5 2.5 12.5 2.5 12.5 2.8 12.5 2.8 12.5 2.8 12.7 2.8 12.7 2.8 13.5 2.8 13.5 2.9 13.5 3.2 13.5 3.2 13.5 8.4 13.5 8.4 13.5 8.8 13.5 8.9 12.7 8.9 12.7 8.9 12.5 8.9 12.5 8.9 12.5 8.9 12.5 9.2 12.5 9.2 12.5 9.2 18.2 9.2 18.2 9.2 18.2 9.2 18.7 6.7 18.7 6.7z"/><path d="M21.7 3.1C21.7 3.1 23 1.1 23 1.1 23.3 0.8 23.6 0.5 24.5 0.5 24.5 0.5 24.5 0.2 24.5 0.2 24.5 0.2 22.1 0.2 22.1 0.2 22.1 0.2 22.1 0.5 22.1 0.5 22.5 0.5 22.7 0.7 22.7 0.9 22.7 1 22.7 1.1 22.6 1.2 22.6 1.2 21.5 2.8 21.5 2.8 21.5 2.8 20.2 0.9 20.2 0.9 20.2 0.9 20.1 0.8 20.1 0.8 20.1 0.7 20.4 0.5 20.8 0.5 20.8 0.5 20.8 0.2 20.8 0.2 20.4 0.2 19.7 0.2 19.3 0.2 19 0.2 18.4 0.2 18 0.2 18 0.2 18 0.5 18 0.5 18 0.5 18.2 0.5 18.2 0.5 18.8 0.5 19 0.5 19.2 0.8 19.2 0.8 21 3.6 21 3.6 21 3.6 19.4 6 19.4 6 19.2 6.2 18.9 6.7 17.9 6.7 17.9 6.7 17.9 7 17.9 7 17.9 7 20.3 7 20.3 7 20.3 7 20.3 6.7 20.3 6.7 19.8 6.7 19.7 6.4 19.7 6.2 19.7 6.1 19.7 6.1 19.8 6 19.8 6 21.2 3.9 21.2 3.9 21.2 3.9 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.4 22.8 6.5 22.6 6.7 22.2 6.7 22.2 6.7 22.2 7 22.2 7 22.5 6.9 23.2 6.9 23.6 6.9 24 6.9 24.5 7 24.9 7 24.9 7 24.9 6.7 24.9 6.7 24.9 6.7 24.7 6.7 24.7 6.7 24.2 6.7 24 6.6 23.8 6.3 23.8 6.3 21.7 3.1 21.7 3.1z"/></g></svg> math...
    </div>
</div>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Jasper Wang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2018 Jasper Wang.
</div>
</body>
</html>
