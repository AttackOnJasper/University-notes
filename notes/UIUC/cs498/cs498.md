# Week 1
- Software defined architecture
	- provides a layer of virtualization between the software and its users
	- allows consumers to interact with a simple application interface while benefiting from complex systems that run hidden in the background.

## Cloudonomics

### Utility Pricing
- Notions
	1. A - Avg demand
	1. B - Baseline (owned) cost (i.e. owning cost per unit time)
	1. C - Cloud unit cost (i.e. renting cost per unit time)
	1. P - Peak demand
	1. t - time needed
	1. U - Utility Premium
- Total cloud cost: $$ C_T = A * C * t $$
- Total baseline cost: $$ B_T = P * B * t $$
- Utility Premium: U = C / B
- When is the cloud cheaper?
	- $$ C_T = A * C * t = A * U * B * t $$
	- If $$ C_T < B_T $$, then A * U < P
		- i.e. When Utility Premium is less than ratio of Peak Demand to Average Demand, Cloud computing is beneficial 
		- In practice, demands are often highly spiky
- Often a hybrid model is the best

### Benefits Common Infrastructure
- Coefficient of variation $$C_v = \frac{\sigma}{\mu}$$ 
	- Measure of smoothness. Smaller -> smoother
	- Adding n independent variables reduces $$C_v $$ by $$\frac{1}{\sqrt{n}}$$
- Multiplexing jobs with different distributions may reduce the coefficient of variation $$C_v$$
	- n independent jobs -> Aggregate $$ C_v = \frac{1}{\sqrt{n}}C_v $$
	- Multiplexing demand in a cloud infrastructure leads to higher utilization
- Cloud providers prefer variable jobs that have negative correlation

## Big Data
- Properties
	1. Volume
	1. Velocity
	1. Variety
	1. Veracity
		- conformity to facts; accuracy


## Tiers of Cloud Services
Multiplexing demands - the physical hardware is shared between multiple tenants. Like a rental car being driven by multiple people as per their time slots.

### IaaS
- when cloud provider provides a virtualized computer e.g. processing, hard drive, disk, network
- users need to set up OS, security features, etc.
- e.g. EC2, S3, Azure, Google cloud platform compute engine
- Benefits comparing to on-prem
	1. No need to run data center
	1. Ops. expenses and Capital expenses
	1. Use instances when needed (based on demands)
- Pricing
	1. On-demand
	1. Reserved
	1. Spot Pricing
- Sub-categories
	1. Metal as a service
	1. Container orchestration

### PaaS
- Main goal is to run the user’s distributed web service in a managed environment
- Cloud provider provides a managed environment. The cloud provider handles OS upgrades, auto-scaling, etc
	- e.g. Load balancers, Queues
- e.g. Azure App service, Google App Engine, Elastic BeanStalk
- Concerns of PaaS vs IaaS
	- Choosing PaaS means that it's harder to move the application from the cloud provider to another

### SaaS

### MBaaS
- Provides a way for mobile web applications to link to backend storage


# Week 2 Network

## Web Intro
- Layers
	1. Application
		- Protocols
			1. HTTP / HTTPS
			1. FTP / SFTP
	1. Transport
		- handles packetizing of data
		- protocols
			1. TCP
				- keeps track of data segments and handles failures
			1. UDP
				- use case: Voice over IP (VoIP)
	1. Internet
		- gets message from one machine to another 
	1. Link
- Middleware
	- Software that provides services to applications beyond those generally available at the operating system
- RMI
	- remote method invocation
- SOA (Service Oriented Architecture)
	- The philosophy of encapsulating application logic in services with a uniformly defined interface and making these publicly available via discovery mechanisms 
	- Benefits
		1. reusable code
		1. interaction
		1. scalability
		1. reduce costs
- Big data RPC Frameworks
	1. Google Protocol Buffer
		- The system automatically generates interfaces functioning as communication stubs in your choice of programming language
	1. Apache Thrift
		- scalable and easy to use the auto-generated RPC functions
- SOAP (Simple object access protocol)
	- Send method execution requests to a remote object
	- Evolved from XML-RPC
	- XML (WSDL) as schema
		- Data representation for (un)marshalling on different machines and programming languages
	- it follows objects, rules, and constraints, SOAP is a more strict protocol than REST
- REST
	- A style of software architecture for distributed hypermedia systems such as the World Wide Web
	- Create, Update, Read, and Remove objects over the web
	- Main concepts
		1. Nouns (resources e.g. URL)
		1. Verbs (e.g. GET, POST)
		1. Representations (e.g. XML)
- Async RPC
	- Web 2.0 supports bidirectional client - server communication
	- Websocket
		- Part of HTML 5 standard
		- Can handle interactive sessions better than RESTful architecture 
		- Use cases: chat, stock price update, collaborative doc editing
		- WebSocket is an application protocol, running on top of TCP
			- URI: `ws://`
		- Phases
			1. Open handshake
			1. Data transfer
			1. Close handshake
		- Javascript W3C WebSocket API event types
			1. Open
			1. Close
			1. Message
			1. Error
		- Cloud provider examples
			1. API gateway
			1. Salesforce
- HTTP/2 Streaming API
	- Use cases: streaming video content, games

## VPC
- What's VPC for?
	- Allow many different users have their own private network in the cloud
- VPC's IP range can be defined
- VPC network does not use ARP while Physical Ethernet Network implements ARP.
- Benefits
	1. security
	1. flexibility
	1. data control
- Subnets
	- VPC is sub-divided into logically separated segments
	- Has a smaller CIDR (Classless Inter-Domain Routing) range comparing to VPC
	- Can have its own routing table
	- Public subnet vs private subnet
- Address allocation of private internets
	- the following three blocks of the IP address space are reserved for private internets
		1. 10.0.0.0/8
		1. 172.16.0.0/12
		1. 192.168.0.0/16
- Gateways
	1. Internet gateway
	1. NAT (Network Address Translation) gateway
		- Virtual router or a gateway in a public subnet that enables instances in a private subnet to interact with the internet
		- Works in Internet layer
		- How it works?
			- looks at the IP packet header and change the IPV4 address with its own address
		- Types
			1. NAT instance (EC2)
			1. NAT gateway (requires elastic IP)
	1. Bastion host
		- Use a bastion host to access private machines hosted in a private network in a VPC
	1. VPG (Virtual Private Gateway)
		- For site-to-site VPN connections
		- The subnet is known as a VPN-only subnet
	1. VPC peering
- Security
	1. Security groups
		- EC2 instance level firewall
		- One or more security groups can be associated with each EC2 instance
		- A security group ID can be specified as a source IP to allow communication from all the instances that are attached to that security group
	1. NACL (Network Access Control Lists)
		- Stateless subnet level firewall
		- Every VPC has a default NACL
		- Every subnet must be associated to one NACL

# Week 3 Serverless
- Categories
	- Compute
		1. PaaS
			- e.g. Elastic Beanstalk, Google App Engine, Azure App service
		1. FaaS (Function)
			- e.g. Lambda
		1. CaaS (Container)
			- e.g. ECS, EKS (Kubernates), Fargate
	- Storage
		1. BLOB (Binary Large OBjects). 
			- e.g. S3
		1. Key / value. 
			- e.g. DynamoDb, Cloudant, Kassandra

## FaaS
- Functions are events that are collected by the cloud backend and trigger your function
- deployment should be stateless, and rely on an external storage service for state storage.

### Lambda
- Features
	1. 500 MB of /tmp storage space
	1. RPC
		- can declare a route through Amazon API Gateway.
	1. Function should finish in a certain time (3 - 300 sec)
	1. Multi-threading support
- Config
	1. Can set how much memory is needed (From 128 MB to 1.5GB)



### Elastic Beanstalk
- Deploy and scale web applications easily

## S3
- Online file storage web service offered by AWS
- Features
	1. Provides web service interfaces including REST, SOAP
	1. Files up to 5 TB
	1. Files are stored in buckets; a bucket has a flat directory structure
- weak consistency model
	- Upon writing a new object to S3, the object might not appear in the list, and S3 might report "key does not exist."
	- Upon updating an existing object in S3 and immediately attempt to read it, users may see the previous version 
	- Upon deleting an object in S3 and immediately attempt to read it, user may still see it

## NoSQL
- examples of NOSQL key/value store cloud offerings
	1. DynamoDB
		- Can think of as a massively distributed B-Tree data structure in the cloud
	1. CosmosDB

## Dropbox 

### API
- Types
	1. Drop-in
		- Functions: create / retrieve files
	1. Core
		- Functions: search, revisions, restoring files
- Auth: OAuth



# Week 4 
- Challenges with traditional programming models MPI (Message Passing Interface)
	1. Deadlock
	1. Inefficient communication mismanagement
	1. Load imbalance
	1. No fault tolerance
- Thus MapReduce is introduced to
	1. use distributed storage
	1. push computations down to storage (to avoid bottleneck of eternet bandwidth)

## MapReduce
- Features
	1. Automatic parallelization and distribution
		- System takes care of load balancing
	1. Fault tolerance
	1. I/O scheduling
	1. Status and monitoring
	1. Easy to write parallel code
- Storage
	- Distributed File System
- Map
	- Perform a function on individual values in a data set to create a new list of values
	- (IN_KEY, IN_VALUE) -> LIST(OUT_KEY, INTERMEDIATE_VALUE)
- Reduce
	- Combine values in a data set to create a new value
	- Typically takes results from the Map function
		- Combines all intermediate values for a particular key
	- (IN_KEY, IN_VALUE) -> LIST(OUT_KEY, INTERMEDIATE_VALUE)
- Challenges
	1. May be hard to express problem in MapReduce
	1. May be hard to utilize data parallism


## Hadoop
- Components
	1. Job tracker (on master machine)
		- Master node
	1. Task tracker (on worker machines)
- Steps
	1. Client submits a job
	1. JobTracker breaks input file into k 64MB chunks and assigns work to Task trackers on map-machines
	1. JobTracker gets notification from Task trackers that map have been completed and then notify reduce-machines
	1. Task trackers on map-machines and reduce-machines exchange map-output
	1. Reduce-machines work on reduce task
	1. reduce() output may go to a distributed file system (e.g. HDFS)
- Init
	1. Split input file into 64MB sections
	1. Fork off program onto multiple machines
	1. Master assigns idle workder machines to either Map or Reduce tasks


### Data pipeline
- System that transforms events into a usable format
- Why migrate to hadoop?
	1. Multi-tenant internal clusters handling TB/day 
	1. Fault-tolerant
	1. Scaling

### YARN (Yet Another Resource Negotiator)
- Hadoop issues
	1. Bottlenecked by JobTracker if cluster has too many nodes
	1. MapReduce abused by other application frameworks
	1. Iterative algorithms were sub-optimal
- Architecture
	1. RM (Resource Manager)
	1. NM (Node Manager)
	1. AM (Application Master)
		- RM launches an AM container via an NM for each application submitted to the cluster
		- AM requests containers via RM; launches containers via NM
		- Uses headroom provided by RM to avoid livelocks
		- Responsible for job history
	1. Containers

### Docker
- Mount a local folder: `docker run -v /Users/daochenw/Desktop/grad/CS498/MPs/MP4/MP4_HadoopMapReduce_Template/PythonTemplate:/python -it sample_image.v1 bin/bash`
- For MP5: `docker run -v /Users/daochenw/Desktop/grad/CS498/MPs/MP5_SparkMapReduce_Template/PythonTemplate:/python -it mp5 bin/bash`
- For MP7: 
	- java: `docker run -v /Users/daochenw/Desktop/grad/CS498/MPs/MP7/MP7_HBase_Template/JavaTemplate:/mp7 -it mp7 bin/bash`
	- python: `docker run -v /Users/daochenw/Desktop/grad/CS498/MPs/MP7/MP7_HBase_Template/PythonTemplate:/mp7 -it mp7 bin/bash`
	- After starting docker
		1. `zkServer.sh start`
		1. `start-hbase.sh`
		1. For python, `hbase thrift start &`
		1. `python TablePartA.py`
- For MP8:
	- python: `docker run -v /Users/daochenw/Desktop/grad/CS498/MPs/MP8_SparkSQL_Template/python:/mp8 --name mp8-cntr -it mp8 bin/bash`

## Apache Spark
- Hadoop issues
	1. Repeated data access to HDFS
	1. No optimization to data caching
- Use cases
	1. Iterative alg.
	1. Interactive data mining
- Features
	1. Integrate with Scala
	1. Can interactively use with Scala interpreter
- Frameworks built on top of Spark
	1. GraphX
		- Google message passing model for graph computation
	1. SparkSQL
		- Database query engine
		- Compatible with Apache Hive
- Implementation
	- Runs on Apache Mesos or YARN
	- Can read from any Hadoop input source
	- Scheduler
		- Dryad-like DAGs
		- Benefits
			1. Improve locality of computation and data
			1. Reduce shuffling of data over network

### RDD (Resilient Distributed Datasets)
- Immutable, partitioned collections of objects
- Features
	1. Allow apps to keep working sets in memory for efficient reuse
	1. Can be cached
- Transformations: map, filter, groupBy, join
- Actions: count, reduce, collect, save
- Fault tolerance
	- maintain lineage information that can be used to reconstruct lost partitions
	- RDD does lazy transformation i.e. won't change data until the actual update action occurs


## HDFS (Hadoop Distributed File System)
- Features
	1. Massive throughput
	1. Optimized for reads, sequential writes and appends
	1. Replicates files
- Typical usage pattern
	1. Huge files (100s of GB to TB)
	1. Data is rarely updated in place
	1. Reads and appends are common
- Implementation
	- DataNode Servers
		- Split files into contiguous chunks of 16 - 64 MB
		- Each chunk replicated
	- NameNode servers


# Week 5: Storage
- Storage Virtualization
	- The process of presenting a logical view of the physical storage resources to a host computer system
	- Types
		1. Block virtualization
		1. File virtualization


## File System
- Middleware between the physical storage device and programs running on top of the OS
- Block storage
	- when the physical device is shown to the operating system as just a medium to store blocks of data
- Layers
	1. Physical 
		- Processes physical blocks being read or written
		- Handles buffering and memory management
		- Interacts with the device drivers
	1. Virtual 
		- e.g. multiple hard-drives
	1. Logical
		- user interaction layer
- inode
	- Provides locations of the data blocks and attributes about the file
		- Internally the data content of a file is stored as a sequence of file system blocks
			- Each block is a fixed number of bytes
- inode table records where each inode is located, indexed by number
- Directories are special files listing the names and inode numbers of files under the folder
- POSIX (Portable Operating System Interface) file systems
	- organized as directories (folders) containing files (documents)
	- APIs
		1. Mount
		1. Open
		1. Seek 
		1. Write
			- Strong consistent
		1. mkdir

## Block storage

### Instance Store
- Sizes
	1. SDD: 80 - 320 GB
	1. HDD: up to 1680 GB
- Benefits
	1. higher performance and bandwidth to the instance.
	1. persist if reboot the machine
- Limitations
	1. the data stored on the drive does not persist, it’s ephemeral
		- data lost when the disk drive fails or when the instance is stopped or terminated
		- can use HDFS / backup by S3 to get reliability
- Use cases
	1. An application that stores 200 GBs of binary data for a few minutes and doesn't need it to be persistent if the instance running it fails


### Virtual Block Stores
- The physical machine running the virtual machine is separate from the physical machine hosting the data
- Features
	1. Highly available and reliable
	1. Up to 16TB
	1. Supports encryption
- Limitation
	1. Data transfer is limited by network bandwidth
- e.g. EBS, Google Cloud Persistent Disk
- EBS

	- A single EC2 instance can be attached to more than 1 EBS volume


## Object Storage
- CAP: Consistency, Availability, Partition Tolerance
	- Consistency: Every read receives the most recent write or an error
	- Availability: Every request receives a (non-error) response, without the guarantee that it contains the most recent write
	- Partition tolerance: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes
	- No way to maintain all 3 components
	- Consistency can be sacrificed
- POSIX compliance generally introduces performance penalty at scale, so cloud object storage typically is not POSIX compliant
- BLOB: a collection of binary data stored as a single entity in a database management system.

### S3
- Features
	1. High availability and partition tolerance
	1. High bandwidth: 25GB/s
	1. Cheap cost
		- Because of the relaxed consistency requirements of S3, building the distributed system to support it is much easier
	1. Data can be accessed outside of cloud via REST call
	

### Swift (Apache Open Stack Blob Service)
- Can store an operating system and application binaries remotely
- Features
	1. API support (GET, PUT)
	1. MD5 Checksums with each object
	1. Auditing and active replication
- Use cases
	1. Unstructured object data like operating system's data and binaries
	1. An application that works with 80 GBs of images on in-house data center


## File System

### Clustered File System
- allows files to be accessed using the same interfaces and semantics as local files
- Features
	1. Fencing (concurrency)
- Limitations
	1. POSIX compliant - hard to maintain CAP on a cluster 
- Examples
	1. NFS (Network File System)
	1. SMB
	1. Lustre
	1. Ceph
		- Use cases
			1. Updating structured data frequently

### Cloud-based FS
- EFS


# Week 6

## Relational 
- Features
	1. ACID (Atomicity, Consistency, Isolation, and Durability)
	1. Replication
	1. OLTP (online transaction processing) workload
- Benefits
	1. allow data recovery for computer / server
	1. querying and finding data is easy
	1. cheap comparing to cache
- Sharding
	- Split data set by certain criteria and store such shards on separate clusters
	- common way to split a database is splitting tables that are not joined in the same query onto different hosts
- Traditional RDBMS (Relational DB Management System)
	- rely on B+Trees, replication, etc. to optimize usage

### Managed Relational Databases
- Features
	1. Fully managed instances
	1. Read replicas
	1. Availability through failover
	1. Encryption at rest and in transport
- Replication 
	- A feature allowing the contents of one or more servers (masters) to be mirrored on one or more servers (slaves)
	- Benefits
		1. Scalability
		1. Backup
	- Options
		1. Classical MySQL Replication
		1. MySQL Group Replication
		1. Multi Master - Galera
		1. MySQL(NDB) Cluster
	- Binary log
		- Maintained in master node
		- Contains a record of all changes to the databases
		- Slaves read (pull mode) the binary log from each master in order to access the data to replicate.
	- Relay log
		- keeps track of the position in the master's binry log of the last event applied on the slave
	- Order of applying changes in slaves
		1. in-order
		1. out-of-order
	- Replication Nature
		1. Async (standard)
		1. Semi-sync
			- Master waits for at least one ACK before committing
				- If no ACK received and timeout, master reverts to async
			- Slower commits than async
		1. GTIDs (global transaction IDs) based Replication
			- Guarantees consistency between master and slave
		1. Multi-Source Replication
			- one server has many masters from which it replicates
	- Replicas
		1. Read replica
			- for scalability
			- nature: async
		1. Multi-AZ
			- for high availability
			- nature
				1. sync for non-Aurora
				1. async for Aurora
		1. Multi-region
			- for disaster recovery
			- nature: async
- Multi Master Cluster
	- Synchronous replication
	- Examples: Galera (MySQL, MariaDB)
- Aurora
	- a database cloud-based, cloud native database solution built on top of MySQL
	- Deuteronomy (Research done by Microsoft)
		- 2 components
			1. Transaction Component
			1. Data Component
	- Features
		1. API compatible with MySQL or Postgres
		1. redo logging
			- stores redo log in database
				- write redo log records to the distributed storage layer, and the storage takes care of constructing page images
			- addresses write amplification
		1. Replication and Quorum
			- Addresses the problems of component failures and performance degradation
			- Write to as many replicas as appropriate to ensure that a quorum read always finds the latest data
		1. Fast repair
			- When a segment fails, the repair of a single protection group only requires moving 10 GB of data, which is done in seconds
			- When multiple protection groups must be repaired, the entire storage fleet participates in the repair process.
		1. Multi-Master
			- No more single point of failure
	- Quorum Read
		- Expensive and should be avoided
		- Needed during recovery on a database instance restart
	- DB Engine Impl
		- a fork of 'community' MySQL/InnoDB
		- InnoDB includes 
			1. IO Subsystem
			1. the transaction subsystem
			1. the lock manager
			1. a B+ Tree impl
			1. the associated notion of a “mini transaction” (MTR)

## NewSQL
- A class of relational database management systems
- Features
	1. Strong consistency (sacrifices some availability)
	1. ACID
- HW-based Time Synchronization providers
	1. NTP
	1. Google Spanner
	1. Azure
	1. Amazon Time Sync Service

### Google Cloud Spanner
- Spanner
	- A distributed data layer that uses optimized sharded Paxos to guarantee consistency
- Features
	1. 2PC (two-phase commit)
	1. TrueTime (external consistency)
		- Heavy use of hardware-assisted clock synchronization using GPS and atomic clocks to ensure global consistency
		- Timestamps become intervals, not single values
	1. Focuses on CP (sacrifices some A - A is in 5 9s range)
	1. Stale reads
		- offer similar performance benefits as eventual consistency but with much stronger consistency guarantees
		- does not block writes
- Paxos
	- Spanner uses the Paxos algorithm to shard (partition) data across hundreds of servers


### Azure CosmosDB
- Globally distributed, multi-model (i.e. many different APIs) database
- Features
	1. Wire compatible with Cassandra
	1. Many API support
	1. Replicated State Machine (RSM) for concurrency
	1. Write-optimized
	1. Automatically indexes everything it ingests
- Indexing
	- BW-Tree indexing
		- Log Structure Record
		- Atom-record-sequence (ARS) system
- Consistency Models
	1. Strong
	1. Bounded-staleness
	1. Session
	1. Consistent Prefix
	1. Eventual

## NoSQL
- NoSQL: not only SQL
- Categories
	1. Key-value
		- Examples
			1. DynamoDB
			1. CosmosDB
	1. Graph DB
	1. Wide Column (BigTable)
	1. Document
- Wide Column key-value Databases
	- Examples
		1. Google BigTable
		1. AWS managed Casandra
- In Memory (Cache) Databases
	1. AWS ElastiCache
	1. Azure
	1. Google
	1. IBM


## MP6
- Connect to RDS
	- `mysql -h dw30-mp6-db-instance-1.ce4vqhqipu92.us-east-1.rds.amazonaws.com -P 3306 -u admin -p`
- Create the DB table
```
CREATE TABLE `sys`.`hero_db` (
  `id` INT NOT NULL,
  `hero` VARCHAR(20) NULL,
  `power` VARCHAR(20) NULL,
  `name` VARCHAR(20) NULL,
  `xp` VARCHAR(20) NULL,
  `color` VARCHAR(20));
```
- General DB commands
	1. `show databases;`
	1. `describe sys.hero_db;`
	1. `select * from sys.hero_db LIMIT 5;`
	1. `DELETE FROM sys.herodb WHERE id >= 26;`

# Week 7

## Cache
- Concepts
	- Principle of locality
		- Tendency of the processor to access the same set of memory locations repetitively over a short period of time
		- Types
			1. Spatial locality
				- certain values are stored very closely in memory
			1. Temporal locality
				- accessing the same value repeatedly across a certain period of time
	- Caching locations
		1. Processor (CPU)
			- L1, L2, L3 cache
			- TLB (Translation Lookaside Buffer)
				- VM address translation
		1. OS
			- VM
			- RAM acts as the “cache” for the SSD
		1. Distributed system
			1. CDN Caching
			1. Web Server Caching
			1. Database Caching
			1. Application Caching
	- Cache Hit
	- Cache Miss
- Cache replacement policies
	1. LRU (least recently used)
	1. TLRU (time-aware LRU)
		- TTU: time to use
	1. LFU (Least Frequently Used)
	1. FIFO
- TTL
	- hacky solution for coherence problem
- Cache writing / updating policies
	1. Cache aside
		- lazy loading
		- Suitable for read-heavy Applications
		- e.g. Memcached
	1. Write thru
		- Pros
			1. No stale data
			1. Read is fast
		- Cons
			1. Cache churn
		- Suitable for write-heavy Applications, where data loss is not acceptable
	1. Write back
		- lazy writing
	1. Write around
		- Writing is only done to the underlying data source
- Cache sharding
	- Memcached
		- Consistent hashing ring alg.
	- Redis
		- up to 250 / 500 shards
	- Problems
		1. Resharding
		1. Celebrity (one data is accessed much more frequently than others; hot partition)
		1. Join and de-normalization
			- Once data is sharded, it's hard to perform join operations across all shards.
- Cache Coherency
	- Whenever cache is distributed, with the same data in more than one place
	- Protocols
		1. Write-invalidate
		1. Write-Update
	- Machisms
		1. Snooping
		1. Directory-based
		1. TTL: Eventually consistent caches


## ElastiCache

### Memcached
- Features
	1. Simple key-value storage model
	1. Simple data model 
	1. No data (persistent) storage
	1. Multi-threaded
	1. Auto discovery
		- Client only needs to connect to the configuration endpoint (a single URL). The Auto Discovery library handles connecting to all of the other nodes
		- Cache node failures are automatically detected; failed nodes are automatically replaced.


### Redis (REmote DIctionary Server)
- Features
	1. dictionary data model
	1. supports strings, list of strings, set of strings
	1. non-blocking I/O
	1. 100,000+ reads/writes per sec
- General use cases
	1. Data that don't mind losing
	1. Key-value pairs
- Use cases
	1. Session store
	1. Logging
- ElastiCache for Redis
	- Replication Group
		- Each replication group has 1 or more node groups
		- Each node group can have 1 master shard and up to 5 other read replicas
- Redis vs Memcached
	- Memcached is generally used to store small and static data, such as HTML code pieces
		- Memory management is efficient and simple
		- Data models are simple
	- Redis supports more complex data structures
		- Fast performance, Persistent storage, Read replicas, Encryption



## Scalable Data Storage

### HBase
- Distributed column-oriented data store built on top of HDFS
	- also a column database
- Why bother?
	- provide storage for Hadoop Distributed Computing
- HDFS is good for batch processing (scans over big files)
- Limitations of HDFS
	1. slow record lookup
	1. incremental addition of small batches
	1. does not support in-place update
- HBase addresses the above limitations
- BigTable is the data model in HBase
	- a sparse (not all data entries need to be filled), distributed, persistent multi-dimensional (multiple versions) sorted map
		- Map indexed by a row key, column key, and a timestamp (timestamp is required)
- Components
	1. Tables
	1. Column families
		- Dynamic columns
- Building blocks
	1. HDFS
	1. ApacheZooKeeper
	1. HFile
		- Stored in HDFS
		- Sequence of blocks on disk plus an index for block lookup
			- on disk file format representing a map from a string to a string
		- Persistent, ordered immutable map from keys to values
	1. HRegion
		- Dynamically partitioned range of rows
		- Built from multiple HFiles
- HRegion Assignment
	- HBase Master keeps track of
		1. Set of live HRegion servers
		1. Assignment of HRegions to HRegion servers 
		1. Unassigned HRegions
	- Each HRegion is assigned to one HRegion server at a time

### SparkSQL
- Structured Data Processing in Apache Spark
- Built on top of RDD data abstraction
- DataSet
	- A distributed collection of data
	- provides the benefits of RDDs
- DataFrame
	- A DataFrame is a Dataset organized into named columns
	- Analogy to a table in a relational DB

### HIVE
- Similar to an SQL database
- HQL, a variant of SQL
	- supports complicated queries on structured data
	- No UPDATE or DELETE support
- Components
	1. Shell
	1. Driver
	1. Compiler
	1. Execution engine
	1. Metastore
		- uses a traditional database to store its metadata including schema, location in HDFS, etc.
		- also has partitioning information



## Message Queues
- SQS
	- put-get-delete paradigm
		- requires a consumer to state that it has finished processing the message pulled from the queue
		- the message data is kept with the queue and gets deleted from the queue only after confirmation that it has been processed
	- message delivery
		- At least once
			- If the client does not respond back to the queue in a specific amount of time, SQS makes it visible again
			- Standard queue
		- Exactly once
			- FIFO queue
	- Short pull vs long pull
- SNS
	- Topics
	- Content
		1. Subject
		1. TTL
		1. Payload
- Kafka
	- A distributed, partitioned, replicated publish subscribe system providing commit log service
	- broker
		- A cluster comprised of one or more servers where Kafka is run
	- Features
		1. Communication uses TCP
		1. messages strictly ordered (within partitions)
	- Use cases
		1. PubSub
		1. Streaming data
	- Kafka Server Cluster Implementation
		- Each topic has partitions
		- partition is replicated across a configurable number of servers
			- Each partition is an ordered, immutable append-only structure
		- Zookeeper is used to keep the servers consistent
	- Offset
		- The position from where the consumer should start consuming
		- Consumer Offsets are per Topic/Partition/ConsumerGroup
	- Consumer Rebalance
		- Each partition will be consumed by exactly one consumer in the entire group


# Week 10: Cloud Analytics

## Terms
1. Analytics
	- the discovery, interpretation, and communication of meaningful patterns in data
1. Business Intelligence (BI)
	- Set of technologies and processes that use data to understand and analyze business performance
	- Typically refer to the necessary but relatively simple questions that will need to be answered frequently
1. Data Analytics
	- the science of examining data to draw conclusions
	- A subset of BI
1. Advanced Analytics
	- More complex statistical techniques and machine learning generate predictions and identify key performance indicators
	- e.g. Fraud detection and recommender systems
1. OLTP
	- typically involve most or all of the columns in a row for a small number of records
	- Each query returns a small number of records
	- RDBMS is suitable
1. OLAP
	- typically read only a few columns for a very large number of rows
	- Data warehouse is suitable


## Data Cubes
- A Datacube is a data structure (a sophisticated nested array)
- Idea
	- transform multi-dimensional data into a 2-D array
- Features
	1. compression schemes
		- SQL databases and data warehouses had to be organized in a way that made for easier cube creation
	1. dimensional modelling
		- common access patterns for OLAP have been identified
			- e.g. Kimball dimensional modeling, Inmon-style entity-relationship modeling
- Operations
	1. Slicing
		- picking a rectangular subset of a cube by choosing a single value for one of its dimensions, creating a new cube with one fewer dimension
	1. Dicing
		- produces a subcube by picking specific values of multiple dimensions
	1. Drill up / down
		- allows the user to navigate among levels of data ranging from the most summarized (up) to the most detailed (down)
	1. Roll up
		- summarizing the data along a dimension
	1. Pivot
		- allows an analyst to rotate the cube in space to see its various faces
- Benefits
	1. Helps OLAP
	1. extreme performance advantage over row-oriented RDBMS
	1. offer richer analysis capabilities than RDBMSs
- Limitations
	1. OLAP cubes require that data teams manage complicated pipelines to transform data from a SQL database into OLAP cubes
	1. Columnar DBs allow performing similar OLAP workloads at equally good performance levels without the requirement to extract and build new cubes
- As of today, OLAP cubes refer specifically to contexts in which these data structures far outstrip the size of the hosting computer's main memory


## Columnar Storage
- aka column-oriented systems, column-stores
- each data element of a record is stored in a column
- Benefits
	1. Less I/O operations if only reading a few columns 
	1. a good fit for analytical workloads that compute aggregates
		- Read optimized
	1. Hardware Optimization
		1. Improves cache utilization and utilizes SIMD (vectorized instructions)
		1. Compression
			- Storing values that have the same data type together offers a better compression ratio
- Features
	1. Metadata
		- identify which data points from other columns it is associated with (to help reconstruct data tuples)
- Column Store File Format
	1. Apache Parquet
		- an open source file format for Hadoop
	1. Apache ORC (Optimized Row Columnar format)
	1. RCFile
- Examples
	1. MonetDB
	1. C-Store
	1. SybaseIQ
- Column-oriented databases should not be mixed up with wide column stores (e.g. BigTable)
	- Data represented as a multi-dimensional map
	- Columns are grouped into column families; inside each column family, data is stored row-wise
	- best for storing data retrieved by a key or a sequence of keys
- Limitations
	1. Update performance is poor
		- Need to every column in order to update one row


## Modern Data Warehouses
- Data Warehouses Architecture motivation
	1. Cloud
	1. MPP (Massively parallel processing)
	1. Columnar storage
	1. Vectorized processing
- Columnar-based Data Warehouses
	1. MariaDB
	1. PostgreSQL
	1. Google BigQuery
	1. AWS Redshift
		- Based on PostgreSQL
		- Blocks are immutable
	1. Microsoft Azure Synapse
		- T-SQL based analytics
		- Deep integration with Apache Spark & Power BI


## Data Lake
- a new type of data repository for storing massive amounts of raw data in its native form, in a single location
	- addresses the limitation of data warehouse - cannot store unstructured big data projects (Petabytes)
- Use case
	- store all data types and analyze that data to make evidence-based business decisions
- Benefits
	1. combine the power of analytics with the flexibility of big data models and the agility and limitless resources of the cloud
- Components
	1. Object Storage
		- e.g. S3
	1. Data Pipeline
		- e.g. AWS Data Pipeline
	1. Data Lake Schema Discovery
		- e.g. Glue
	1. SQL Exploration and Query
		- e.g. Athena
	1. Lake Formation
		- Automated tools to orchestrate the data transfer, discovery, ETL and analytics steps
		- e.g. AWS Lake Formation


## Other Analytics Services
- Serverless Analytics
	- e.g. Azure Analysis services, Redshift Spectrum, Athena
- Search-based Analytics
	- ELK Stack
		1. ElasticSearch
		1. Logstash
		1. Kibana
- Big Data Analytics
	- e.g. Managed Hadoop, Spark, Hive
- Graphical BI
	- e.g. Tableau, QuickSight, PowerBI


### AWS Glue
- AWS Glue is a serverless data integration service that allows analytics users to discover, prepare, move, and integrate data from multiple sources.
- Data sources: Amazon Redshift, Amazon S3, Amazon RDS, and Amazon DynamoDB
- Terminologies
	1. Data catalog
		- The persistent metadata store
		- Contains table definitions, job definitions, and other control information
		- Each AWS account has one AWS Glue Data Catalog per region
	1. Classifier
		- Determines the schema of your data
		- Glue provides classifiers for common file types, such as CSV, JSON, AVRO, XML
	1. Crawler
		- A program that 
			1. connects to a data store (source or target)
			1. progresses through a prioritized list of classifiers to determine the schema for the data
			1. then creates metadata tables in the AWS Glue Data Catalog.
	1. Glue studio
		- A graphical interface for users to create and edit your AWS Glue jobs visually 
- Documentation
	- https://docs.aws.amazon.com/glue/latest/dg/components-key-concepts.html
- SQL (via Athena)
```
SELECT f1.airline as Airline, f1.origin_airport as Origin_Airport, f1.destination_airport as Stopover_Airport, f2.destination_airport as Destination_Airport, f1.departure_delay as Origin_Departure_Delay, f1.arrival_delay as Stopover_Arrival_Delay, f2.departure_delay as Stopover_Departure_Delay, f2.arrival_delay as Destination_Arrival_Delay
FROM "AwsDataCatalog"."mp9-db"."flights" f1
JOIN "AwsDataCatalog"."mp9-db"."flights" f2
ON f1.airline = f2.airline
AND f1.destination_airport = f2.origin_airport
WHERE f1.origin_airport = 'SFO'
AND f2.destination_airport = 'JFK'
AND f2.day*24*60 + (f2.scheduled_departure / 100)*60 + (f2.scheduled_departure % 100) + f2.departure_delay - (f1.day*24*60 + (f1.scheduled_departure / 100)*60 + (f1.scheduled_departure % 100) + f1.departure_delay + f1.elapsed_time + ((f1.scheduled_arrival / 100)*60 + (f1.scheduled_arrival % 100) - ((f1.scheduled_departure / 100)*60 + (f1.scheduled_departure % 100) + f1.scheduled_time)%(24*60))) BETWEEN 60 and 180
AND f1.cancelled = 0
AND f2.cancelled = 0
```




# Week 11: Graph Processing and Machine Learning
- Graph Basics
	- Node
	- Edges
	- Local traversal
		- one that starts at a particular vertex (or small set of vertices) and touches a small set of connected vertices.

## Graph DB
- A graph database is any storage system that provides index-free adjacency
	- with an explicit graph structure
	- Index-free adjacency: each node directly stores references to its adjacent nodes rather than relying on indexes or pointers
- Features
	1. Associative data sets
	1. Structure of object-oriented applications
	1. Do not require join operators
	1. Scales well
	1. Can be faster than relational, particularly for graph-type queries
- Addresses the following RMDBS limitation
	- hard to identify related data among different tables e.g. 1-to-many, many-to-many
	- need to use join operations
- Categories
	1. OLTP-based graph systems
		- allow the user to query the graph in real-time
		- Examples
			1. Neo4j
				- An open-source, NoSQL, native graph database that provides an ACID-compliant transactional backend
				- Cypher,a declarative query language similar to SQL, but optimized for graphs
			1. TinkerPop & Gremlin
				- Supports both OLTP queries and OLAP algorithms
				- A traversal in Gremlin is a series of chained steps like BFS
			1. Amazon Neptune
			1. Azure CosmosDB
	1. OLAP-based graph systems
		- the entire graph is processed
		- Bulk Synchronous Parallel (BSP) programming model
			- Pregel -> Giraph -> Spark GraphX -> GraphFrames

## Graph Processing
- Limitation of MapReduce on graph processing
	1. Graph computations involve local data (small part of graph surrounding a vertex)
	1. The connectivity between vertices is sparse
		- The data may not all fit into one node
	1. each computational stage will produce much communication between stages
- Limitation of existing shared memory parallel graph algorithms
	1. No fault-tolerance


### Pregel
- One of the first systems to do graph processing on a distributed system
- Input & output: directed graphs
- Idea: Repeats until every computation at each vertex votes to halt
- features
	1. vertex based
	1. implemented using C++
	1. No guarantees on message delivery order
	1. Messages in Pregel are delivered exactly once.
- Superstep
	- Each iteration of computation
	- Within each superstep, the following operations can be applied on a vertex
		1. Can get/set Vertex value
		1. Can get/set outgoing edges values
		1. Can send/receive messages
- Architecture
	- Master 
		- maintains workers
		- recovers faults of workers
		- provides web UI monitoring
	- Worker
	- Execution
		1. master assigns a partition of the input to each worker
		1. master instructs each worker to perform a superstep
			- Each worker loops through vertices
			- Messages are delivered before the end of the superstep
	- Storage
		- Persistent data - Distributed storage
		- Temporary data - Local disk
- Fault Tolerance
	- Checkpointing
		- The master periodically instructs the workers to save the state of their partitions to persistent storage
	- Failure detection
		- Using regular “ping” messages
	- Recovery
		- Master reassigns graph partitions to the currently available workers
		- Workers all reload their partition state from most recent available checkpoint


### Apache Giraph
- Open source based on pregel
- Giraph Framework
	1. ZooKeeper
		- responsible for computation state
		- ensures eventual consistency
		- scaling
	1. JobTracker (Master)
		- responsible for coordination
		- organizes tracker
	1. TaskTracker
		- contains workers
		- worker responsible for vertices
	1. Worker



### Spark GraphX
- an Apache Spark's graph processing module
- Idea: parallel computation on all of the vertices of a graph, or all of the edges of a graph
- Operators
	1. Create a graph
		- Input: RDD of vertices and RDD of edges
	1. Query the vertices and edges of a graph
	1. Transformations
		1. Reverse
		1. Subgraph
		1. mapVertices
		1. mapEdges
	1. Join
	1. Computation



## ML in clouds
- Data Mining & Machine Learning are subsets of AI
- AI applications: info retrieval, stats, biology, linear algebra, marketing

### ML Workflows
- OSEMN Data Science Model
	1. Obtain
	1. Scrub
		- Data Preparation and Data Wrangling
	1. Explore
		- Inspect data, data wrangling, analyze data
	1. Model
		- Feature engineering
		- Model training
		- Evaluation
	1. Interpret
- Hyper Parameters
	- Parameters about the training of the model
		- e.g. number of iterations
	- AutoML strategies (for tuning hyper parameters)
		1. Grid search
		1. Random search
		1. Gradient descent
- AutoML
	- AutoML strategies + Auto select algorithms
	- Examples
		1. Azure ML
		1. Google AutoML
		1. AWS Sagemaker autopilot


## Cloud ML Offerings
- ML frameworks
	- Mahout (big data)
- Managed Platforms
	1. Google Cloud AI platform
		- Managed notebooks
		- AI Platform Training
		- Kubeflows
	1. Azure ML
		- Managed platform
		- Managed Jupyter notebooks
	1. AWS SageMaker
		- Process
			1. Label
			1. Build
			1. Train & Tune
			1. Deploy & manage
		- Training alg.s are packaged as Docker images


## Human-in-the-loop AI
- use selective inclusion of human participation
- Benefits
	1. Gain in transparency
	1. Human judgment
	1. No need to build the perfect AI system
- Offerings
	1. SageMaker Ground Truth


## Unstructured data ML
- Vision
	- AWS Rekognition
- Voice
	- Polly, Lex
- Language
	- Polly, Lex


## Apache Spark
- Collection of ML libraries
- Algorithms
	- Collaborative filtering
		- Have multiple filters working together to extract just the information you want.
		- Algs
			- Alternating Least Squares
			- Stochastic Gradient Descent
		- Example: recommendation engine working based on the user preferences and others with similar preferences
	- Clustering
		- K-means
			- Can use MapReduce to iterate centroid computation
			- Optimizations
	- Classification
		- Naive Bayes
			- a simple multiclass classification algorithm with the assumption of independence between every pair of features.
- FPM (Frequent Pattern Mining)
	- use case: Finding the frequent item sets frequently bought together
	- FP-growth algorithm






# Week 12: Streaming
- Prior data processing mechanisms cannot deal with data in real-time
	- e.g. MapReduce, Hadoop
- Cloud stream engines
	1. Apache Storm
	1. Twitter Heron
	1. Apache Flink


## Apache Storm
- Features
	1. Guaranteed data processing
	1. Horizontal scalability
	1. Fault tolerance
	1. lambda architecture
- Concepts
	1. Streams
		- Unbounded sequences of tuples
	1. Spout
		- Source of Streams
	1. Bolts
		- Containers that processes input streams and produces new streams
		- can perform transformation, filter, aggregation, join, etc.
	1. Topologies
		- Network of spouts and bolts
- Grouping ways (when a tuple is emitted, which task does it go to?)
	1. Shuffle grouping
		- pick a random task
	1. Fields grouping
		- consistent hashing on a subset of tuple fields
	1. All grouping
		- send to all tasks
	1. Global grouping
		- pick task with lowest id
- Components
	1. Nimbus (master node)
	1. Zookeeper
		- Cluster coordination
	1. Supervisor
		- Worker processes
	1. Cluster
		- Structure
			- Clojure (functional programming language) and Java
	1. Scheduler
		- IScheduler
			- interface; has schedule method to be implemented
		- Multitenant scheduler
			- A specific implementation of the IScheduler interface that is designed to support multi-tenancy in a Storm cluster
			- Multi-tenancy refers to the ability to run multiple topologies from multiple users on a single Storm cluster
- Thrift
	- framework for scalable cross-language services development
	- can also use thrift compiler for storm
		

## Approaching guarantee message processing
1. None
1. At Least Once
	- Methods
		1. tuple trees
			- A spout tuple is not fully processed until all tuples in the tree have been completed
			- Acker tasks keep track of the tree, and the tree will be replayed if not completed within a timeout
			- Anchoring
				- when emit occurs (i.e. an output is emitted), anchoring creates a new edge in the tuple tree
				- An ack call marks a single node in the tree as complete
	- Upon failure
		- can double process events
		- requires having a spout that supports replay.
1. Exactly Once
	- needs to store the state of storm tasks
	- Trident
		- state is a first-class citizen
		- provides a high level API
		- no acking required



## Spark Streaming
- Stateful Stream processing
- Process
	1. Window a bit of data (Chop up the live stream into batches of X seconds; X >= 0.5)
	1. Run a batch
	1. Repeat
- Advantages
	1. Rich ecosystem of big data tools
- Disadvantages
	1. Not really streaming (latency 1s)
- Use case
	- Potential for combining batch processing and streaming processing in the same system

## Lambda and Kappa architecture
- Lambda
	- A parallel processing pipeline of two branches: a stream processing pipeline and a batch processing pipeline
	- Has real time processing of events that come into the data pipeline
	- e.g. storm
- Kappa
	- idea: fix the streaming pipeline to a point that it can handle failures
		- Only one stream processing (+ batch processing) pipeline but with the ability to handle failures
	- Can use Microbatch for state
	- e.g. spark

## Streaming ecosystem
- General steps
	1. Gather the Data
		- NiFi
			- Great visual UI to design a data flow
	1. Distributed Queue
		- pub-sub model
	1. Distributed Processing
	1. Micro batch processing / SQL / ML
	1. OLAP
		- e.g. Druid





# Week 13: Virtualization
- Virtualization: allows distributed computing models without creating dependencies on physical resources
	- creates a layer of abstraction between the physical resource and the software that runs on it
- Process Isolation
	- a virtualized idealized machine should allow each process to think that they basically own that idealized machine.
- To isolate processes from each other, the OS has two modes
	1. Kernel Mode
		- Privileged instructions execute only in kernel mode
		- Run in CPU ring 0
	1. User Mode
		- User process operate in user mode
		- When the user application requests a service from the OS, or an interrupt occurs, or a system call is made, there will be a transition from user to kernel mode to fulfill the requests
		- Run in CPU ring 3


## Terms
1. Privileged Instruction
	- an instruction that requires a higher level of privilege or access than a typical user or application would have
		- When a privileged instruction is executed, the CPU checks whether the process is allowed or not. If not allowed, CPU would issue General Protection Fault (GPF)
	- often used to manage system resources or perform low-level operations that are critical to the functioning of the system
1. Privileged Operations
	- Certain operations are not allowed in user mode code
	- Examples: HLT, INVLPG, LIDT, MOV CR registers
1. Process
	- An image of the program’s executable machine code
1. Sensitive instruction
	- instructions or operations that have the potential to cause harm or unintended consequences if they are not executed properly.
	- e.g. loading memory mapping tables, accessing I/O devices, interrupts
	

## Types of virtualizations
- Emulation
	- write a software program that would basically emulate that CPU and emulate everything else 
	- e.g. GBA emulator, Android emulator, Xcode iPhone emulator
- Full
	- The VM simulates enough hardware to allow an unmodified "guest" OS to be run in isolation
		- e.g. set up VM by running a guest OS in an X86 host platform 
	- The VM looks and feels exactly like a real computer
	- Creates virtual barriers between multiple virtual environments running in the same physical environment
	- e.g. VirtualBox, Virtual PC, VMWare, QEMU
	- Types
		1. Software
		1. Hardware
- MicroVMs
	- Virtualize the absolute minimum kernel of computing
	- Used by AWS Lambda and Fargate
- OS level
	- e.g. Containers

## Full Virtualization

### Software-based virtualizations

#### Paravirtualization
- A technique in which a modified guest OS kernel communicates to the hypervisor its intent to perform privileged CPU and memory operations
- First approach to oftware-only Virtualization
- The virtual machine does not necessarily simulate hardware, but instead offers a special API that can only be used by modifying the "guest" OS
- e.g. Xen
	- Invasive changes to the kernel to run Linux as a paravirtualized guest
	- Concepts
		- Dom0 (Control Domain)
			- GuestOS basically asks the Xen hypervisor in the Dom0 to do priv. instructions on behalf of them so they don't need to talk to hardware themselves.
		- Guest Domain
			- User apps
		- Driver / Stub / Service Domain
			- A "driver, device” model or “control service in a box"
			- De-privileged and isolated
			- Talk to Xen provided virtual mem / network
	- EC2 was relying on Xen


#### Binary Translation
- modifies sensitive instructions (ring 0) on the fly to virtualizable ("safe") instructions 
- performed on the binary code that gets executed on the processor


### Hardware assisted
- sometimes the hardware, the CPU, has hardware features that help full virtualization
- Terms
	1. VMM: virtual machine manager (hypervisor)
	1. MMU: memory management unit
- Generations
	1. Guest mode is introduced to support direct execution of guest code including privileged kernel code
		- A new instruction **vmrun** transfers from host to guest mode.
		- Limitation
			- lacks explicit support for memory virtualization (i.e. does not virtualize MMU)
	1. Many issues of the first-gen are resolved
	1. accelerates nested virtualization of VMMs
		- introduces IOMMU virtualization


## OS-Level Virtualization / Containers
- Isolation problem of OS
	- OS apparently don't do a good job of providing isolation
	- Initially hypervisor was used to address this
	- Now docker / containers are better solutions for some use cases
- Idea: "Virtualizing" a physical server at OS level, enabling multiple isolated and secure virtualized servers to run on a single physical server
	- No more hypervisors / guest OS
- Can be treated as OS level virtualization; however, it's not virtualization as virtualization requires relies on hypervisors and all sorts of additional technology trap and emulate
	- Processes think they see a virtual kernel, but are all sharing the same real kernel under the hood
	- Can refer to as 'light-weight' virtualization
- e.g. Solaris Containers, FreeBSD Jails, Linux Containers (Docker - 2013)
- VM vs Containers
	- VM
		- 1 real HW, many virtual HW, many OS
	- Containers
		- 1 real HW, no virtual HW, one kernel
		- higher density
		- dynamic resource allocation
		- native performance; almost no overhead
- The liunx features that enable connectors
	1. cgroups (control groups)
		- Linux kernel feature which limits, isolates and measures resource usage of a group of processes
		- Cloud provider can use it to limit CPU, RAM on a container
		- Process
			1. Create a control group and assign resource limits on it
				- Controllers mounted in the cgroups file system
			1. Add a process id to the group
	1. Namespaces
		- wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource
	1. Unionfs (Union file system)
		- can appear to merge the contents of several directories (branches), while keeping the physical content separate
		- Backbone of container images
		- Provides layer capabilities
- chroot() does NOT provide secure isolation


### Docker
- An engine that allows you to do containers
- Docker image
	- a stack of immutable or read-only layers
	- In run-time, the docker engine adds a R/W layer on top of the stack of immutable layers
- Graph Driver
	- The driver to handle the cache of Docker image layer (cache stored by the local instance of Docker engine)
- Docker Architecture
	- Linux OS
		- Components: cgroups, namespaces, unionfs
	- Runtime
		- Components
			1. containerd 
				- based on runc
			1. runc
				- low-level functionality of the container runtime
				- Spawns and runs containers according to the Open Container Initiative (OCI) specification
	- Docker engine
		- Components
			1. Libcontainerd
			1. Libnetwork
			1. graph
			1. plugins
			1. A REST interface over which all container operations can be automated
				- Docker CLI uses the REST interface
- Container Network Model
	- Formalizes the steps required to provide networking for containers while providing an abstraction that can be used to support multiple network drivers
	- Components
		1. Sandbox
			- contains the configuration of a container's network stack.
		1. Endpoint
			- An Endpoint joins a Sandbox to a Network.
				- Can be thought as a virtual network adaptor
		1. Network
			- A group of Endpoints that are able to communicate with each-other directly
			- Implementation: Linux bridge, VLAN
	- Default drivers in Docker Libnetwork
		1. Bridge
		1. Host
		1. Overlay
		1. macvlan



# Week 14: Container Orchestration and Infrastructure as Code

## Docker Foundations
- Dockerfile
	- A mechanism that tells Docker Engine what layers you want to have in a particular image and how they are built one layer on top of another.
	- Multi stage 
		- allows us to not include unnecessary intermediate layers
- Besides using Dockerfile to create container image, one can also start a container using existing image and install necessary packages on top of it to create a new image. 

## Docker Swarm Orchestration
- An application may have different components running on different containers
	- We need an orchestra conductor to guide various containers running together
- We can utilize Docker Swarm / Docker Compose
- Docker Swarm
	- Docker native orchestrator
	- Declarative model; users define the desired state
	- State
		1. image name and tag
		1. num of containers in the service
		1. ports exposed to clients outside of swarm
	- Task states
		- examples: NEW, PENDING, and COMPLETE


## Docker Networking
- Bridge
	- default networking when `--network` is not specified
	- connects container to the `my-net` network
	- All containers in `my-net` network have access to all other ports
		- This is risky operation as it allows unrelated services to communicate
	- Ports can be published from container so that external clients can access
- Overlay
	- creates a distributed network among multiple Docker daemon hosts
	- overlays the host-specific networks


## Service Discovery in Docker Swarm
- DNS lookup
- For most situations, you should connect to the service name, which is load-balanced and handled by all containers (“tasks”) backing the service.


## External load balancing in Docker Swarm
- Internal load balancing: when one container or one service wants to talk about another service on the same network
	- Done via VIP
- Routing Mesh
	- Features
		1. enables each node in the swarm to accept connections on published ports for any service running in the swarm.
		1. uses port based service discovery and load balancing.
		1. auto route the incoming traffic to a node that has a service task running on it.
	- Services using the routing mesh are running in virtual IP (VIP) mode.
	- By default all nodes participate in an ingress routing mesh.
- Docker acts as a load balancer for swarm services (can think of swarm services as a single super computer)
- External load balancing methods
	1. Routing mesh
		- HAProxy
	1. Disables VIP endpoint mode, which allows a DNS query for the service name returning a list of IP addresses


## Ways to map host to container
1. Bind mount
	- Directory on host machie is mounted into a container
	- Persistent data storage
1. Volume
	- Virtualized disk drive managed by Docker
	- Persistent storage abstraction
	- Removed when container is removed
1. tmpfs
	- temp file system
	- storage is not on host machine or within the container
	- use cases
		1. security reasons
		1. protect the performance of the container

## Docker Compose (single host)
- Main tool by Docker for container orchestration 
- Uses `docker-compose.yml` (declarative way)
- Used by AWS ECS and Azure ACI






# Week 15: Kubernates
- A platform for distributed systems to orchestrate the deployment, scaling, and management of container-based applications
- Features
	1. primary responsibility: container orchestration
	1. replace dead, unresponsive, or unhealthy containers
- Advantages
- Building blocks

## Terms
1. Cluster
	- A collection of hosts (nodes) that provide compute, memory, storage, and networking resources
1. Nodes
	- host (virtual / physical machines)

## Architecture
- Components
	- Master node (Control plane)
		- responsible for the global state of the cluster, cluster-level scheduling of pods, and handling of events
		- User define num of master nodes
		- Features
			1. horizontal scaling
		- Components
			1. API server
			1. Controller manager
			1. Scheduler
			1. etcd
				- distributed highly available consistent key-value store
				- Used to store the state of the cluster
		- kubectl (command line tool) converts user commands to API calls
	- Worker node
		- Components
			1. kubelet
				- communicates with master node and manages the pods
			1. kube-proxy
				- Manages routing of requests and traffic for both the node and the pods
			1. container-runtime
				- The component that interacts with the OS, launches containers, and manages namespaces
- Kubernetes runs workloads by placing containers into Pods to run on (worker) Nodes
- Namespace
	- Kubernetes supports multiple virtual clusters backed by the same physical cluster
	- These virtual clusters are namespaces
	- NOT the same as Linux namespace feature


## Pod 
- A special Kubernetes construct that groups one or more containers that share some namespaces
- Smallest control unit in Kubernetes
- Pod container design patterns
	- Single Node patterns
		1. Sidecar
			- 2 containers: app & sidecar
			- Sidecar container augments and improves the app container
				- e.g. adding HTTPS on top of HTTP, dynamic configuration
		1. Ambassador
			- app container only talks to ambassador container, and ambassador container talks to external services on behalf of app container
		1. Adapter


## Higher Level Resource Abstractions
- Labels
	- Labels are key/value pairs that are attached to object
		- e.g. pods
	- Functions
		1. can be used to organize and select subsets of objects
		1. enable users to map their own organizational structures onto system objects
- Label Selectors
	- used to select objects based on their labels
	- core grouping primitive in Kubernetes


## Kubernetes Service
- An abstraction which defines a logical set of Pods running somewhere in your cluster, that all provide the same functionality.
	- e.g. A pool of HTTP servers
- Functions
	1. manages pods' life cycles
- The service pattern is micro-service

## Networking
- kube-proxy (on worker node)
	- functions
		1. watches the Kubernetes control plane for the addition and removal of Service and Endpoint objects (e.g. a pod)
		1. responsible for implementing a form of virtual IP for Services
	- Every node in a Kubernetes cluster runs a kube-proxy.
	- Modes
		1. User space proxy mode
		1. iptables proxy mode
		1. IPVS proxy mode
- Users don't need to take care of mapping container ports to host ports.

## Kubernates vs Docker Swarm
- Docker swarm 
	- a little bit more opinionated i.e. it kind of assumes that a certain way of doing networking
	- Each task has only 1 container
	- Networking happens thru routing mesh
	- SDNs are used to firewall containers
- Kubernates 
	- allows customize a lot of things
	- Each pods can have 1 or more containers
	- Networking has more flexibility; Service provides an abstraction that defines a logical set of pods and a policy
	- A single flat network is used
	- Cannot directly run a container in Kubernetes cluster




# Week 16: Future Developments in the Cloud
- Thirteen Predictions
	1. Adoption of cloud computing will continue to grow rapidly
	1. The cloud will become more global
	1. Regulated industries will move to the cloud
		- e.g. GDPR
	1. Storage capacity will continue to increase rapidly. SSD's share of the market will grow, but there will still be a lot of HDD and magnetic tape in use
	1. The cloud will continue to support AI, and there is a symbiotic / mutually-beneficial relationship between AI and clouds 
		- Digital Transformation
	1. The data center accelerator market growth will explode
	1. The future of cloud computing access is mobile
	1. FaaS will continue to grow in popularity and use
		- According to Gartner, IaaS is likely to grow the fastest over the next few years
	1. Low-code / No-code / Citizen Development will become increasingly important to the industry, as it is a way to help deal with the predicted 1 million software developer shortfall in the U.S.
	1. Increased adoption of clouds means increased risks of security breaches
		- Threats
			1. Incomplete data deletion
			1. Vulnerabilities in management APIs
			1. Multi-tenant data leakage due to failure of separation of control
			1. Insider abuse
		- IaaS is preferred for security reason
	1. IoT will grow and help fuel the growth of the cloud industry
	1. Hybrid clouds / multi clouds/ omni clouds will become more feasible and widely-used
		- Containers become mainstream
		- Anthos
			- mostly based on Kubernates
	1. The demand for cloud professionals will grow