# CS 475

## Lecture 1 (2018-05-02)
### Prerequisites
- Basic linear algebra and calculus
- Scientific programming (Matlab, Python, Julia)
- Mathematical Maturity

### Assignments
- A1: 05-02 - 05-23 (10%)
- A2: 05-23 - 06-11 (10%)
- A3: 06-13 - 07-04 (10%)
- A4: 07-04 - 07-23 (10%)
- Always acknowledge the source of help (e.g. google, stackoverflow)
- No late submissions

### Exams
- Midterm: 06-13 10:00 - 11:20 MC 2065 20% (open book)
- Final: 40% (open book)

### Outline
- Matrix Decompositions
	- LU. Gaussion Elimination
	- Cholesky
	- PDEs
	- Graph representation and ordering
	- Inverse problems
- Iterative method
	- Splitting
	- Steepset descent
	- Least-squares
	- Conjugate gradient
	- Projections
- Spectral Decomposition
	- QR decomposition
	- Reflection & Rotations
	- Eigen-value decomposition
	- Rayleigh Quotient
	- Subspace iteration
	- SVD (singular-value decomposition)

### Definitions
- **Linear algebra** studies the properties and operations of linear maps between 2 vector spaces
- **Computational linear algebra** studies the **implementation** of the operations on a modern computer

### Applications
- top 10 algs. in science & engineering for 20th century
	- Metropolis alg. for Monte Carlo (covered)
	- Simplex
	- Krylor Subspace (covered)
	- Decomposition algs (covered)
	- Fortran
	- QR (covered)
	- Quicksort
	- FFT (fast fourier transform)
	- Integer relation detection
	- Fast Muti-pole alg.
- Page Rank (Priority of a search result)
	- Assume n webpages on the internet with a probability vector **v**, pick an arbitrary webpage $$ S_{0} = j $$
		- toss a coin at time t
			- head: click a (random) link on webpage $$ S_{t} $$ to transfer to $$ S_{t+1} $$. If no link on $$ S_{t} $$, restart from $$ S_{0} $$
			- tail: go to  $$ S_{t+1} = k with probability v_{k} $$
		- in the long run, how often am I on each webpage k? (the frequency reflects the **importance** of a website; this is how google calculate pagerank)
	- Math
		- Initial distribution: start from webpage j
		- Transistion Matrix $$ P_{ij} = P_{r}(S_{t+1} = i | S_{t} = j) $$
			- column-stockestic matrix
		- Teleportation 
		- Biased Coin
		- Define $$ x_{t}(i) $$ as the prob of being on webpage i at time t, $$ \vec x_{t+1} = \alpha * P * \vec x_{t} + (1 - \alpha) * \vec V = [\alpha P + (1 - \alpha)\vec v 1^T ]\bar P * \vec x_{t} $$. $$ \vec x_{t} $$ is a prob vector that sums up to 1 i.e. $$ \vec x^T1 = 1 $$
	- Ergodic Theorem: $$ \frac{1}{T} \sum_{t=1}^{T}1(S_{t} = i) -> x(i) $$ where $$ \vec x = \bar P * \vec x $$
		- \vec x is an eigenvector of P, with eigenvalue 1
	- $$ (I - \alpha * \bar P) * \vec x = (1 - \alpha) * \vec v $$
	- $$ x = \bar P * x $$
- Semi-supervised learning / dimensionality reduction
- Graph-cut
- Information retrieval

### Notations
- **x**, **x$$_{t}$$**, $$x_{i}$$, $$x_{t,i}$$

## Lecture 2 (2018-05-07)
### Objectives
- $$ \bar P \vec x = \vec x, \bar P = \alpha P + (1 - \alpha)\vec v 1^T $$
- $$ (I - \alpha P)\vec x = (1 - \alpha)\vec v $$

### Matlab
- j-th column of A - $$ A_{:,j} $$
- i-th row: $$ A_{i,:} $$

### Matrix Multiplication
- $$ A \in \Re^{m*n}, B \in \Re^{n*p}, C = A * B \in \Re^{m*p} $$ complexity O(mnp)
- Strassen's alg. $$ O(n^{2.89}) $$

### Matrix Inverse
- A is invertable if and only if $$ A \in \Re^{n*n} $$ and $$ A^{-1}*A = A * A^{-1} = I $$
- Thm (Sherman-Morrisen-Woodbury): $$ A\in\Re^{n*n}, B\in\Re^{m*m}, u\in\Re^{n*m}, V\in\Re^{n*m}, (A + uBV)^{-1} = A^{-1} - A^{-1}u(B^{-1}+V^TA^{-1}u)^{-1}V^TA^{-1} $$
	- In particular, $$ (A + \vec u \vec v)^{-1} = A^{-1} - \frac{1}{1+v^TA^{-1}u}A^{-1}uv^TA^{-1} $$
	- Proof: verify that the product is 1

### Goal: solve $$ A\vec x = \vec b, A \in \Re^{n*n} $$, A is invertible
- $$ \vec x = A^{-1}\vec b $$ is non-trivial for computer implementation
- e.g. $$ 	\begin{cases} 
				2x + y + 2z = 1 \\
				4x + 2y -z = 2 \\
				x + y + 2z = 3
			\end{cases} $$
- to solve a linear system, try to transform the matrix 
	$$ \begin{bmatrix}
		2 & 1 & 2 \\ 
		4 & 2 & -1 \\
		1 & 1 & 2
	\end{bmatrix} $$ to an upper triangular matrix
- Psedo code for solving lower triangular matrix $$ O(n^2) $$
	- 	```
		for n = 1, 2, ... n do
			$ y_i = (b_i - l^T_{i,1:(i-1)}y_{1:(i-1)})/l_{ii}; $
		```
	- **Problem** division of $$ l_{i,i} $$ could be 0. 
		- solution: add a small number to all diagonals to avoid such issues / pivoting
- During implementation, try to use vector instead of for-loop for calculation (avoid loop as much as possible)
- Gaussian Elimination psedo code
	- Input: $$ A \in \Re^{n*n}, \vec b \in \Re^{n*1} $$
	- output: in-place transform A to upper triangular matrix
	- code:
		```
		for j = 1,2 ... n-1 do
			for i = j + 1, ..., n do
			$$	a_{i,j} <- a_{i,j} / a_{j,j} $$
			$$	\vec a_{i,j+1:n} <- \vec a_{i,j+1:n} - a_{ij} $$
		```
	- still have the problem of division
		- how to guarantee that the diagnals are never zero? 
		- solution: compute the **determinent**: $$ det(A) = \sum_{\sigma}(-1)^{sgn(\sigma)} * \prod^{n}_{i=1} A_{i, \sigma(i)} $$

### Thm (LU factorization): let $$\widetilde{L}$$ and u be the strict lower triangular and upper triangular part of the output of GE, then A = L*u, $$ L = \widetilde{L} + I $$

### Solve linear system
- note: don't use inverse ever!
- $$ \begin{aligned}
		A\vec x = \vec b, A &= Lu \\
 		Lu\vec x &= \vec b \\
		L\vec y &= \vec b, u\vec x = \vec y
\end{aligned} $$
- use forward solve to get y and backward solve to get x, time complexity is $$ O(n^3) $$
